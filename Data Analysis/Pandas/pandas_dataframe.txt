2 dimensional table
info() return a summary

sum() add by tranversing the index; axis = 1/'index'/'column' to across columns

selecting multiple columns

.insert(loc:numeric index position)
.value_counts(normalize = )

drop rows with missing values
.dropna(how = 'any') default
.dropna(how = 'all')
.dropna(subset = [''])

fill missing values
.fillna()

.astype('int'/int) same
astype('category') rather than object reduce memory usage
.nunique()
.sort_values(by = '', ascending = ,na_position = 'last'/'first')
.sort_values(['',''], ascending = ['', ''])

.sort_index()
.rank() assigns a numeric ranking to sech series value
#nba['Salary Rank'] = nba['Salary'].rank(ascending = False).astype(int)

pd.to_datetime(pd.Series, format = ''/%m%d%Y/) 
also work for time, format = '%H:%M %p'

dt.time
read_csv(parse_dates = True)

multiple
.isin(collection object, series, list, tuple), return True for a row is value is found

Filter based on condition
pd.to_datetime(df[], format = '%H:$M %p).dt.time
dt.timme()

isnull and notnull methods
.isnull()
.notnull()
.between()
.duplicated(keep = 'first'/'last'/False)


.set_index()

iloc[] requires numeric position for rows and columns
loc[] requires labels for rows and columns

overwrite multiple values
dataframe['col name'].replace('original','new')
loc can also do the same thing

rename
data.rename(columns = {'original':'new', ...}, index = {})

dataframe.drop(columns = [], index = [])
dataframe.pop(single column)
del bond['Year'] 

data.sample() get a random row
data.sample(n = 5, axis = 'rows'/'columns')

bond.sort_values('box office', ascending = False).head(4)
bond.nlargest(n=4,columns='box office')
bond['box office'].nlargest(4)

.where()
.str.split("", expand = True, n = 1(number of split))

def quality(t1, t2):
  ... two columns...

df[['total_bill','tip']].apply(lambda df:quality(df['total_bill'], df['tip']))
axis = 1)
np.vectorize(quality)(df['total_bill'],df['tip'])

df.sort_values(['tip','size'])
df.corr()
df[].value_counts()
df[].unique()
df[].nunique()
df[].replace('','')
mymap = {}
df.map(mymap)

pd.DateFrame([1,2,2],['a','b','c'])
df.drop_duplicate()
df.between(10,20,inclusive = True) - True, False
df.nlargest(10,column name)
df.sample(frac = )

